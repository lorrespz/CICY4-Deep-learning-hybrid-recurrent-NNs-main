{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8488978,"sourceType":"datasetVersion","datasetId":4575883},{"sourceId":180758667,"sourceType":"kernelVersion"}],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# CICY4: LSTM-448 [5-fold-CV] - Fold-4","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport random\nimport pandas as pd\nimport os as os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom datetime import datetime\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim.lr_scheduler as lr_scheduler","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-31T12:23:18.115358Z","iopub.execute_input":"2024-05-31T12:23:18.115814Z","iopub.status.idle":"2024-05-31T12:23:24.184422Z","shell.execute_reply.started":"2024-05-31T12:23:18.115780Z","shell.execute_reply":"2024-05-31T12:23:24.183620Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2024-05-31T12:23:24.185965Z","iopub.execute_input":"2024-05-31T12:23:24.186412Z","iopub.status.idle":"2024-05-31T12:23:24.219533Z","shell.execute_reply.started":"2024-05-31T12:23:24.186385Z","shell.execute_reply":"2024-05-31T12:23:24.218576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seed = 42\n\ndef seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n\nseed_everything(seed)","metadata":{"execution":{"iopub.status.busy":"2024-05-31T12:23:24.220678Z","iopub.execute_input":"2024-05-31T12:23:24.221018Z","iopub.status.idle":"2024-05-31T12:23:24.233214Z","shell.execute_reply.started":"2024-05-31T12:23:24.220991Z","shell.execute_reply":"2024-05-31T12:23:24.232250Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" # LSTM-based network architecture","metadata":{}},{"cell_type":"code","source":"class LSTM_block(nn.Module):\n    def __init__(self, n_inputs, n_hidden, n_rnnlayers, n_outputs):\n        super(LSTM_block,self).__init__()\n        self.D = n_inputs\n        self.M = n_hidden\n        self.K = n_outputs\n        self.L = n_rnnlayers\n        self.lstm = nn.LSTM(input_size = self.D,\n                           hidden_size = self.M,\n                           num_layers = self.L,\n                           batch_first = True)\n\n        self.feat_vec_size = self.M\n        self.fc1 = nn.Linear(self.feat_vec_size, 1024)\n        self.fc2 = nn.Linear(1024, 4)\n    def forward(self, X):\n        #input X is NxTxD\n        #initial hidden states\n        h0 = torch.zeros(self.L, X.size(0), self.M).to(device)\n        c0 = torch.zeros(self.L, X.size(0), self.M).to(device)\n        #get LSTM unit output:\n        #output is NxTxM\n        out, _ = self.lstm(X, (h0,c0))\n        #we only want the output y at the final time step\n        # output is now of shape (N, M)\n        xx = out[:, -1, :]\n        xx = self.fc1(xx)\n        #final output is 4\n        xx = self.fc2(xx)\n        return xx","metadata":{"execution":{"iopub.status.busy":"2024-05-31T12:23:24.235441Z","iopub.execute_input":"2024-05-31T12:23:24.235764Z","iopub.status.idle":"2024-05-31T12:23:24.245254Z","shell.execute_reply.started":"2024-05-31T12:23:24.235738Z","shell.execute_reply":"2024-05-31T12:23:24.244358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = LSTM_block(20, 448, 2, 4)\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-05-31T12:23:24.246482Z","iopub.execute_input":"2024-05-31T12:23:24.246850Z","iopub.status.idle":"2024-05-31T12:23:24.596090Z","shell.execute_reply.started":"2024-05-31T12:23:24.246815Z","shell.execute_reply":"2024-05-31T12:23:24.595068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#count the number of parameters in the model\nparams = [p.numel() for p in model.parameters() if p.requires_grad]\nprint(f'Total numbers of parameters: {sum(params)}')","metadata":{"execution":{"iopub.status.busy":"2024-05-31T12:23:24.597258Z","iopub.execute_input":"2024-05-31T12:23:24.597548Z","iopub.status.idle":"2024-05-31T12:23:24.602928Z","shell.execute_reply.started":"2024-05-31T12:23:24.597523Z","shell.execute_reply":"2024-05-31T12:23:24.601871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load data (fold-0) & define dataset class","metadata":{}},{"cell_type":"code","source":"# load data\npath = '/kaggle/input/cicy4-data-for-5-fold-cv/'\nX_train = np.load(path + 'foldx_4_Xtrain.npy')\nX_valid = np.load(path +'foldx_4_Xval.npy')\ny_train = np.load(path+'foldx_4_ytrain.npy')\ny_valid = np.load(path+'foldx_4_yval.npy')\n\n#Test set is the original test set from the 72% dataset\npath2 = '/kaggle/input/calabi-yau-cicy-4-folds/'\nX_test = np.load(path2+'conf_Xtest.npy')\ny_test= np.load(path2+'hodge_ytest.npy')\n\nprint(X_train.shape, X_valid.shape, X_test.shape)\nprint(y_train.shape, y_valid.shape, y_test.shape)\nprint(y_train.shape[0]/905684, y_valid.shape[0]/905684, y_test.shape[0]/905684)","metadata":{"execution":{"iopub.status.busy":"2024-05-31T12:23:24.603941Z","iopub.execute_input":"2024-05-31T12:23:24.604193Z","iopub.status.idle":"2024-05-31T12:23:32.522210Z","shell.execute_reply.started":"2024-05-31T12:23:24.604161Z","shell.execute_reply":"2024-05-31T12:23:32.519256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Convert data to torch tensor with float32 precision\n#(needed to be compatible with the floating decision of the network parameters)\nX_train = torch.from_numpy(X_train.astype(np.float32))\ny_train = torch.from_numpy(y_train.astype(np.float32))\n\nX_valid = torch.from_numpy(X_valid.astype(np.float32))\ny_valid = torch.from_numpy(y_valid.astype(np.float32))\n\nX_test = torch.from_numpy(X_test.astype(np.float32))\ny_test= torch.from_numpy(y_test.astype(np.float32))","metadata":{"execution":{"iopub.status.busy":"2024-05-31T12:23:32.523097Z","iopub.status.idle":"2024-05-31T12:23:32.523500Z","shell.execute_reply.started":"2024-05-31T12:23:32.523309Z","shell.execute_reply":"2024-05-31T12:23:32.523325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CICY4Dataset(torch.utils.data.Dataset):\n    def __init__(self, X, y):\n        self.X = X\n        self.y = y\n    def __len__(self):\n        return len(self.X)\n    def __getitem__(self, idx):\n        X0 = self.X[idx]\n        y0 = self.y[idx]\n        return X0, y0\n\ntrain_set = CICY4Dataset(X_train, y_train)\nval_set = CICY4Dataset(X_valid, y_valid)\ntest_set = CICY4Dataset(X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2024-05-31T12:23:32.525144Z","iopub.status.idle":"2024-05-31T12:23:32.525619Z","shell.execute_reply.started":"2024-05-31T12:23:32.525362Z","shell.execute_reply":"2024-05-31T12:23:32.525382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\ntrain_loader = DataLoader(train_set, batch_size=128, shuffle=True)\nval_loader = DataLoader(val_set, batch_size=128, shuffle=True)\ntest_loader = DataLoader(test_set, batch_size=128, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-05-31T12:23:32.526810Z","iopub.status.idle":"2024-05-31T12:23:32.527259Z","shell.execute_reply.started":"2024-05-31T12:23:32.527026Z","shell.execute_reply":"2024-05-31T12:23:32.527045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Utility functions","metadata":{}},{"cell_type":"code","source":"def train_one_epoch(model, criterion, optimizer, train_loader):\n    model.train()\n    train_loss = []\n    for inputs, target in train_loader:\n        inputs, target = inputs.to(device), target.to(device)\n        optimizer.zero_grad()\n        out = model(inputs)\n        loss = criterion(out, target)\n        loss.backward()\n        optimizer.step()\n        train_loss.append(loss.item())\n    #average the train_loss list in for all batches in the train_gen\n    train_loss = np.mean(train_loss)\n    return train_loss","metadata":{"execution":{"iopub.status.busy":"2024-05-31T12:23:32.528538Z","iopub.status.idle":"2024-05-31T12:23:32.529021Z","shell.execute_reply.started":"2024-05-31T12:23:32.528782Z","shell.execute_reply":"2024-05-31T12:23:32.528802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def validate_one_epoch(model, criterion, optimizer, val_loader):\n    model.eval()\n    test_loss = []\n    for inputs, target in val_loader:\n        inputs, target = inputs.to(device), target.to(device)\n        out = model(inputs)\n        loss = criterion(out, target)\n        test_loss.append(loss.item())\n    #average the test_loss list in for all batches in the test_gen\n    test_loss = np.mean(test_loss)\n    return test_loss","metadata":{"execution":{"iopub.status.busy":"2024-05-31T12:23:32.530494Z","iopub.status.idle":"2024-05-31T12:23:32.530847Z","shell.execute_reply.started":"2024-05-31T12:23:32.530678Z","shell.execute_reply":"2024-05-31T12:23:32.530693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def batch_gd_scheduler(model, new_model_name, criterion, optimizer, train_loader, val_loader, scheduler,\n                         epochs, device, batch_size=128):\n    train_losses = np.zeros(epochs)\n    test_losses = np.zeros(epochs)\n    patience = 0\n    best_loss = 1000\n    max_patience = 20\n    for i in range(epochs):\n        t0 = datetime.now()\n        train_loss = train_one_epoch(model, criterion, optimizer,train_loader)\n        test_loss = validate_one_epoch(model, criterion, optimizer,val_loader)\n        #Early stopping based on test loss\n        if i == 0:\n            best_loss = test_loss\n            torch.save(model, f'/kaggle/working/{new_model_name}.pt')\n            #torch.save(model, path+f'{new_model_name}.pt')\n            print(f'Model saved as {new_model_name} at epoch {i}')\n        else:\n            if test_loss < best_loss:\n                best_loss = test_loss\n                torch.save(model, f'/kaggle/working/{new_model_name}.pt')\n                #torch.save(model, path+f'{new_model_name}.pt')\n                print(f'Model overwritten at epoch {i}, new best val loss {best_loss}')\n                patience = 0\n            else:\n                patience = patience +1\n                #print(f'No improvement, current patience level is {patience} at epoch {i}')\n        if patience > max_patience:\n            print(f'Max patience reached, training is terminated at epoch {i}')\n            break\n        #Apply scheduler after the train+validate parts\n        before_lr = optimizer.param_groups[0][\"lr\"]\n        scheduler.step(test_loss)\n        after_lr = optimizer.param_groups[0][\"lr\"]\n        train_losses[i] = train_loss\n        test_losses[i] = test_loss\n        #write the losses into a csv file\n        loss_dict = {'train_loss': train_losses, 'val_loss': test_losses}\n        dd = pd.DataFrame(loss_dict)\n        dd.to_csv('loss_dict_lstm_448_fold4.csv', index = False)\n        dt = datetime.now()-t0\n        if i%10==0:\n            print(f'Epoch: {i}/{epochs}, train loss: {train_loss: .3f}, val_loss: {test_loss: .3f}, duration: {dt}, learning rate: {before_lr, after_lr}')\n    return train_losses, test_losses\n","metadata":{"execution":{"iopub.status.busy":"2024-05-31T12:23:32.532374Z","iopub.status.idle":"2024-05-31T12:23:32.532749Z","shell.execute_reply.started":"2024-05-31T12:23:32.532543Z","shell.execute_reply":"2024-05-31T12:23:32.532557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_from_scratch_or_load(load_model_weight,new_model_name, epochs):\n    if load_model_weight==None:\n        #criterion = nn.MSELoss()\n        criterion = nn.HuberLoss()\n        optimizer = torch.optim.AdamW(model.parameters(), lr=0.01)\n        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.1, min_lr = 1e-8)\n        train_losses, test_losses=batch_gd_scheduler(model, new_model_name, criterion,\n                                                     optimizer,train_loader, val_loader,\n                                                      scheduler, epochs,\n                                                       device = device)\n        return train_losses, test_losses\n    else:\n        if torch.cuda.is_available():\n            trained_model = torch.load(load_model_weight)\n        else:\n            trained_model = torch.load(load_model_weight, map_location=torch.device('cpu'))\n        return trained_model","metadata":{"execution":{"iopub.status.busy":"2024-05-31T12:23:32.534453Z","iopub.status.idle":"2024-05-31T12:23:32.534805Z","shell.execute_reply.started":"2024-05-31T12:23:32.534632Z","shell.execute_reply":"2024-05-31T12:23:32.534646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_and_retrain(load_model_weight, new_model_name, epochs):\n    trained_model = torch.load(load_model_weight)\n    print('Trained model loaded')\n    criterion = nn.HuberLoss()\n    optimizer = torch.optim.AdamW(trained_model.parameters(),lr=0.01)\n    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.1, min_lr = 1e-7)\n    trained_model.train()\n    print('Begin retraining')\n    train_losses, test_losses=batch_gd_scheduler(trained_model,new_model_name, criterion, optimizer,\n                                                 train_loader, val_loader,\n                                                 scheduler, epochs,\n                                                 device = device)\n    return trained_model, train_losses, test_losses","metadata":{"execution":{"iopub.status.busy":"2024-05-31T12:23:32.535938Z","iopub.status.idle":"2024-05-31T12:23:32.536284Z","shell.execute_reply.started":"2024-05-31T12:23:32.536095Z","shell.execute_reply":"2024-05-31T12:23:32.536112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_losses(train_losses, test_losses):\n    # Plot the train loss and test loss per iteration\n    plt.plot(train_losses, label='train loss')\n    plt.plot(test_losses, label='val loss')\n    plt.legend()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-31T12:23:32.537671Z","iopub.status.idle":"2024-05-31T12:23:32.538013Z","shell.execute_reply.started":"2024-05-31T12:23:32.537845Z","shell.execute_reply":"2024-05-31T12:23:32.537859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"################## GET PREDICTIONS + ACCURACY #####################\ndef get_pred_n_acc(models, device, dataloader, num_iter):\n    i = 0\n    ypreds =[]\n    targets = []\n    #The last batch might not have size 128\n    while i< num_iter:\n        for data, target in dataloader:\n            #this empty list is to hold all models' preds\n            ypred = []\n            data= data.to(device)\n            data = data.to(torch.float32)\n            target = target.to(torch.float32)\n            #append the 'i^th' target\n            targets.append(target)\n            for model in models:\n                model.eval()\n                yp = model(data)\n                yp = yp.detach().cpu().numpy()\n                ypred.append(yp)\n            #take the mean of all models' predictions\n            ypred = np.array(ypred).mean(axis = 0)\n            ypred = np.round(ypred)\n            i+=1\n            #append ypred, targets inside the 'i' loop\n            # append the 'i^th' mean prediction\n            ypreds.append(ypred)\n            if i == num_iter:\n                break\n     #Do not convert ypreds, targets to np.array at this point,\n    #since the last batch has a different size, causing an error !\n    #CALCULATING ACCURACY\n    yp =  np.concatenate([ypreds[j] for j in range(len(ypreds))], axis = 0)\n    tgs =  np.concatenate([targets[j] for j in range(len(targets))], axis = 0)\n    h11_acc = ((yp[:,0] == tgs[:,0]).sum())/len(yp)\n    h21_acc = ((yp[:,1] == tgs[:,1]).sum())/len(yp)\n    h31_acc = ((yp[:,2] == tgs[:,2]).sum())/len(yp)\n    h22_acc = ((yp[:,3] == tgs[:,3]).sum())/len(yp)\n    acc = [h11_acc*100,h21_acc*100,h31_acc*100,h22_acc*100 ]\n    return  yp, tgs, acc\n","metadata":{"execution":{"iopub.status.busy":"2024-05-31T12:23:32.539409Z","iopub.status.idle":"2024-05-31T12:23:32.539864Z","shell.execute_reply.started":"2024-05-31T12:23:32.539626Z","shell.execute_reply":"2024-05-31T12:23:32.539646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train loop","metadata":{}},{"cell_type":"code","source":"load_model_weight = None\nepochs = 550\nnew_model_name = 'LSTM-448-d80-fold4'\nif load_model_weight is None:\n    train_losses, test_losses=train_from_scratch_or_load(load_model_weight,new_model_name,  epochs)\nelse:\n    model, train_losses, test_losses=load_and_retrain(load_model_weight, new_model_name, epochs)","metadata":{"execution":{"iopub.status.busy":"2024-05-31T12:23:32.540892Z","iopub.status.idle":"2024-05-31T12:23:32.541315Z","shell.execute_reply.started":"2024-05-31T12:23:32.541092Z","shell.execute_reply":"2024-05-31T12:23:32.541111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_losses(train_losses, test_losses)","metadata":{"execution":{"iopub.status.busy":"2024-05-31T12:23:32.543344Z","iopub.status.idle":"2024-05-31T12:23:32.543830Z","shell.execute_reply.started":"2024-05-31T12:23:32.543561Z","shell.execute_reply":"2024-05-31T12:23:32.543596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Accuracies","metadata":{}},{"cell_type":"code","source":"#Train accuracy\nyt, tgt, acct = get_pred_n_acc([model], device, train_loader, num_iter = len(train_loader))\n#validation accuracy\nyv, tgv, accv = get_pred_n_acc([model], device, val_loader, num_iter = len(val_loader))\nprint(f'Train data, target shapes: {yt.shape, tgt.shape},\\n train accuracies {acct}')\nprint(f'Validation data, target shapes: {yv.shape, tgv.shape},\\n validation accuracies {accv}')\n","metadata":{"execution":{"iopub.status.busy":"2024-05-31T12:23:32.545062Z","iopub.status.idle":"2024-05-31T12:23:32.545395Z","shell.execute_reply.started":"2024-05-31T12:23:32.545227Z","shell.execute_reply":"2024-05-31T12:23:32.545241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Test accuracy\nyts, tgts, accts = get_pred_n_acc([model], device, test_loader, num_iter = len(test_loader))\nprint(f'Test data, target shapes: {yts.shape, tgts.shape},\\n test accuracies {accts}')\n","metadata":{"execution":{"iopub.status.busy":"2024-05-31T12:23:32.546991Z","iopub.status.idle":"2024-05-31T12:23:32.547354Z","shell.execute_reply.started":"2024-05-31T12:23:32.547175Z","shell.execute_reply":"2024-05-31T12:23:32.547189Z"},"trusted":true},"execution_count":null,"outputs":[]}]}