{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24482bb3",
   "metadata": {
    "papermill": {
     "duration": 0.008004,
     "end_time": "2024-06-01T11:01:08.264525",
     "exception": false,
     "start_time": "2024-06-01T11:01:08.256521",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# CICY4: LSTM-448 [5-fold-CV] - Fold-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32398530",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-06-01T11:01:08.281531Z",
     "iopub.status.busy": "2024-06-01T11:01:08.281140Z",
     "iopub.status.idle": "2024-06-01T11:01:13.819319Z",
     "shell.execute_reply": "2024-06-01T11:01:13.818458Z"
    },
    "papermill": {
     "duration": 5.549562,
     "end_time": "2024-06-01T11:01:13.821765",
     "exception": false,
     "start_time": "2024-06-01T11:01:08.272203",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import os as os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim.lr_scheduler as lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdde3c6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-01T11:01:13.837678Z",
     "iopub.status.busy": "2024-06-01T11:01:13.837228Z",
     "iopub.status.idle": "2024-06-01T11:01:13.893019Z",
     "shell.execute_reply": "2024-06-01T11:01:13.892100Z"
    },
    "papermill": {
     "duration": 0.065803,
     "end_time": "2024-06-01T11:01:13.895004",
     "exception": false,
     "start_time": "2024-06-01T11:01:13.829201",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2527b5d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-01T11:01:13.910625Z",
     "iopub.status.busy": "2024-06-01T11:01:13.910364Z",
     "iopub.status.idle": "2024-06-01T11:01:13.918363Z",
     "shell.execute_reply": "2024-06-01T11:01:13.917566Z"
    },
    "papermill": {
     "duration": 0.0179,
     "end_time": "2024-06-01T11:01:13.920278",
     "exception": false,
     "start_time": "2024-06-01T11:01:13.902378",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_everything(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0000fd1",
   "metadata": {
    "papermill": {
     "duration": 0.007033,
     "end_time": "2024-06-01T11:01:13.934899",
     "exception": false,
     "start_time": "2024-06-01T11:01:13.927866",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    " # LSTM-based network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18cf94bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-01T11:01:13.950827Z",
     "iopub.status.busy": "2024-06-01T11:01:13.950267Z",
     "iopub.status.idle": "2024-06-01T11:01:13.959564Z",
     "shell.execute_reply": "2024-06-01T11:01:13.958635Z"
    },
    "papermill": {
     "duration": 0.019558,
     "end_time": "2024-06-01T11:01:13.961530",
     "exception": false,
     "start_time": "2024-06-01T11:01:13.941972",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LSTM_block(nn.Module):\n",
    "    def __init__(self, n_inputs, n_hidden, n_rnnlayers, n_outputs):\n",
    "        super(LSTM_block,self).__init__()\n",
    "        self.D = n_inputs\n",
    "        self.M = n_hidden\n",
    "        self.K = n_outputs\n",
    "        self.L = n_rnnlayers\n",
    "        self.lstm = nn.LSTM(input_size = self.D,\n",
    "                           hidden_size = self.M,\n",
    "                           num_layers = self.L,\n",
    "                           batch_first = True)\n",
    "\n",
    "        self.feat_vec_size = self.M\n",
    "        self.fc1 = nn.Linear(self.feat_vec_size, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 4)\n",
    "    def forward(self, X):\n",
    "        #input X is NxTxD\n",
    "        #initial hidden states\n",
    "        h0 = torch.zeros(self.L, X.size(0), self.M).to(device)\n",
    "        c0 = torch.zeros(self.L, X.size(0), self.M).to(device)\n",
    "        #get LSTM unit output:\n",
    "        #output is NxTxM\n",
    "        out, _ = self.lstm(X, (h0,c0))\n",
    "        #we only want the output y at the final time step\n",
    "        # output is now of shape (N, M)\n",
    "        xx = out[:, -1, :]\n",
    "        xx = self.fc1(xx)\n",
    "        #final output is 4\n",
    "        xx = self.fc2(xx)\n",
    "        return xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f2b71a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-01T11:01:13.977156Z",
     "iopub.status.busy": "2024-06-01T11:01:13.976859Z",
     "iopub.status.idle": "2024-06-01T11:01:14.320219Z",
     "shell.execute_reply": "2024-06-01T11:01:14.319312Z"
    },
    "papermill": {
     "duration": 0.353299,
     "end_time": "2024-06-01T11:01:14.322243",
     "exception": false,
     "start_time": "2024-06-01T11:01:13.968944",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM_block(\n",
       "  (lstm): LSTM(20, 448, num_layers=2, batch_first=True)\n",
       "  (fc1): Linear(in_features=448, out_features=1024, bias=True)\n",
       "  (fc2): Linear(in_features=1024, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LSTM_block(20, 448, 2, 4)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ce677ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-01T11:01:14.339532Z",
     "iopub.status.busy": "2024-06-01T11:01:14.339209Z",
     "iopub.status.idle": "2024-06-01T11:01:14.344521Z",
     "shell.execute_reply": "2024-06-01T11:01:14.343638Z"
    },
    "papermill": {
     "duration": 0.016691,
     "end_time": "2024-06-01T11:01:14.346494",
     "exception": false,
     "start_time": "2024-06-01T11:01:14.329803",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total numbers of parameters: 2915332\n"
     ]
    }
   ],
   "source": [
    "#count the number of parameters in the model\n",
    "params = [p.numel() for p in model.parameters() if p.requires_grad]\n",
    "print(f'Total numbers of parameters: {sum(params)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5dd1bc0",
   "metadata": {
    "papermill": {
     "duration": 0.007392,
     "end_time": "2024-06-01T11:01:14.361384",
     "exception": false,
     "start_time": "2024-06-01T11:01:14.353992",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load data (fold-4) & define dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17bd8d79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-01T11:01:14.377541Z",
     "iopub.status.busy": "2024-06-01T11:01:14.377288Z",
     "iopub.status.idle": "2024-06-01T11:01:35.953077Z",
     "shell.execute_reply": "2024-06-01T11:01:35.951985Z"
    },
    "papermill": {
     "duration": 21.586166,
     "end_time": "2024-06-01T11:01:35.955295",
     "exception": false,
     "start_time": "2024-06-01T11:01:14.369129",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(579638, 16, 20) (144909, 16, 20) (181137, 16, 20)\n",
      "(579638, 4) (144909, 4) (181137, 4)\n",
      "0.640000264993088 0.1599995141793385 0.2000002208275734\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "path = '/kaggle/input/cicy4-data-for-5-fold-cv/'\n",
    "X_train = np.load(path + 'foldx_4_Xtrain.npy')\n",
    "X_valid = np.load(path +'foldx_4_Xval.npy')\n",
    "y_train = np.load(path+'foldx_4_ytrain.npy')\n",
    "y_valid = np.load(path+'foldx_4_yval.npy')\n",
    "\n",
    "#Test set is the original test set from the 72% dataset\n",
    "path2 = '/kaggle/input/calabi-yau-cicy-4-folds/'\n",
    "X_test = np.load(path2+'conf_Xtest.npy')\n",
    "y_test= np.load(path2+'hodge_ytest.npy')\n",
    "\n",
    "print(X_train.shape, X_valid.shape, X_test.shape)\n",
    "print(y_train.shape, y_valid.shape, y_test.shape)\n",
    "print(y_train.shape[0]/905684, y_valid.shape[0]/905684, y_test.shape[0]/905684)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56cf2b17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-01T11:01:35.971965Z",
     "iopub.status.busy": "2024-06-01T11:01:35.971663Z",
     "iopub.status.idle": "2024-06-01T11:01:36.436096Z",
     "shell.execute_reply": "2024-06-01T11:01:36.435095Z"
    },
    "papermill": {
     "duration": 0.475483,
     "end_time": "2024-06-01T11:01:36.438612",
     "exception": false,
     "start_time": "2024-06-01T11:01:35.963129",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Convert data to torch tensor with float32 precision\n",
    "#(needed to be compatible with the floating decision of the network parameters)\n",
    "X_train = torch.from_numpy(X_train.astype(np.float32))\n",
    "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
    "\n",
    "X_valid = torch.from_numpy(X_valid.astype(np.float32))\n",
    "y_valid = torch.from_numpy(y_valid.astype(np.float32))\n",
    "\n",
    "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
    "y_test= torch.from_numpy(y_test.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28313022",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-01T11:01:36.455427Z",
     "iopub.status.busy": "2024-06-01T11:01:36.455086Z",
     "iopub.status.idle": "2024-06-01T11:01:36.461211Z",
     "shell.execute_reply": "2024-06-01T11:01:36.460268Z"
    },
    "papermill": {
     "duration": 0.016701,
     "end_time": "2024-06-01T11:01:36.463132",
     "exception": false,
     "start_time": "2024-06-01T11:01:36.446431",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CICY4Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    def __getitem__(self, idx):\n",
    "        X0 = self.X[idx]\n",
    "        y0 = self.y[idx]\n",
    "        return X0, y0\n",
    "\n",
    "train_set = CICY4Dataset(X_train, y_train)\n",
    "val_set = CICY4Dataset(X_valid, y_valid)\n",
    "test_set = CICY4Dataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17c6cbad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-01T11:01:36.479256Z",
     "iopub.status.busy": "2024-06-01T11:01:36.478944Z",
     "iopub.status.idle": "2024-06-01T11:01:36.484104Z",
     "shell.execute_reply": "2024-06-01T11:01:36.483257Z"
    },
    "papermill": {
     "duration": 0.015457,
     "end_time": "2024-06-01T11:01:36.485909",
     "exception": false,
     "start_time": "2024-06-01T11:01:36.470452",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79076f1a",
   "metadata": {
    "papermill": {
     "duration": 0.007157,
     "end_time": "2024-06-01T11:01:36.500782",
     "exception": false,
     "start_time": "2024-06-01T11:01:36.493625",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "802e1d0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-01T11:01:36.516709Z",
     "iopub.status.busy": "2024-06-01T11:01:36.516443Z",
     "iopub.status.idle": "2024-06-01T11:01:36.522009Z",
     "shell.execute_reply": "2024-06-01T11:01:36.521174Z"
    },
    "papermill": {
     "duration": 0.015715,
     "end_time": "2024-06-01T11:01:36.523865",
     "exception": false,
     "start_time": "2024-06-01T11:01:36.508150",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model, criterion, optimizer, train_loader):\n",
    "    model.train()\n",
    "    train_loss = []\n",
    "    for inputs, target in train_loader:\n",
    "        inputs, target = inputs.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(inputs)\n",
    "        loss = criterion(out, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss.append(loss.item())\n",
    "    #average the train_loss list in for all batches in the train_gen\n",
    "    train_loss = np.mean(train_loss)\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98bc2d37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-01T11:01:36.539600Z",
     "iopub.status.busy": "2024-06-01T11:01:36.539344Z",
     "iopub.status.idle": "2024-06-01T11:01:36.544594Z",
     "shell.execute_reply": "2024-06-01T11:01:36.543852Z"
    },
    "papermill": {
     "duration": 0.015126,
     "end_time": "2024-06-01T11:01:36.546406",
     "exception": false,
     "start_time": "2024-06-01T11:01:36.531280",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validate_one_epoch(model, criterion, optimizer, val_loader):\n",
    "    model.eval()\n",
    "    test_loss = []\n",
    "    for inputs, target in val_loader:\n",
    "        inputs, target = inputs.to(device), target.to(device)\n",
    "        out = model(inputs)\n",
    "        loss = criterion(out, target)\n",
    "        test_loss.append(loss.item())\n",
    "    #average the test_loss list in for all batches in the test_gen\n",
    "    test_loss = np.mean(test_loss)\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09f9651c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-01T11:01:36.562533Z",
     "iopub.status.busy": "2024-06-01T11:01:36.562296Z",
     "iopub.status.idle": "2024-06-01T11:01:36.572348Z",
     "shell.execute_reply": "2024-06-01T11:01:36.571457Z"
    },
    "papermill": {
     "duration": 0.020369,
     "end_time": "2024-06-01T11:01:36.574249",
     "exception": false,
     "start_time": "2024-06-01T11:01:36.553880",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def batch_gd_scheduler(model, new_model_name, criterion, optimizer, train_loader, val_loader, scheduler,\n",
    "                         epochs, device, batch_size=128):\n",
    "    train_losses = np.zeros(epochs)\n",
    "    test_losses = np.zeros(epochs)\n",
    "    patience = 0\n",
    "    best_loss = 1000\n",
    "    max_patience = 20\n",
    "    for i in range(epochs):\n",
    "        t0 = datetime.now()\n",
    "        train_loss = train_one_epoch(model, criterion, optimizer,train_loader)\n",
    "        test_loss = validate_one_epoch(model, criterion, optimizer,val_loader)\n",
    "        #Early stopping based on test loss\n",
    "        if i == 0:\n",
    "            best_loss = test_loss\n",
    "            torch.save(model, f'/kaggle/working/{new_model_name}.pt')\n",
    "            #torch.save(model, path+f'{new_model_name}.pt')\n",
    "            print(f'Model saved as {new_model_name} at epoch {i}')\n",
    "        else:\n",
    "            if test_loss < best_loss:\n",
    "                best_loss = test_loss\n",
    "                torch.save(model, f'/kaggle/working/{new_model_name}.pt')\n",
    "                #torch.save(model, path+f'{new_model_name}.pt')\n",
    "                print(f'Model overwritten at epoch {i}, new best val loss {best_loss}')\n",
    "                patience = 0\n",
    "            else:\n",
    "                patience = patience +1\n",
    "                #print(f'No improvement, current patience level is {patience} at epoch {i}')\n",
    "        if patience > max_patience:\n",
    "            print(f'Max patience reached, training is terminated at epoch {i}')\n",
    "            break\n",
    "        #Apply scheduler after the train+validate parts\n",
    "        before_lr = optimizer.param_groups[0][\"lr\"]\n",
    "        scheduler.step(test_loss)\n",
    "        after_lr = optimizer.param_groups[0][\"lr\"]\n",
    "        train_losses[i] = train_loss\n",
    "        test_losses[i] = test_loss\n",
    "        #write the losses into a csv file\n",
    "        loss_dict = {'train_loss': train_losses, 'val_loss': test_losses}\n",
    "        dd = pd.DataFrame(loss_dict)\n",
    "        dd.to_csv('loss_dict_lstm_448_fold4.csv', index = False)\n",
    "        dt = datetime.now()-t0\n",
    "        if i%10==0:\n",
    "            print(f'Epoch: {i}/{epochs}, train loss: {train_loss: .3f}, val_loss: {test_loss: .3f}, duration: {dt}, learning rate: {before_lr, after_lr}')\n",
    "    return train_losses, test_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "332bf336",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-01T11:01:36.590763Z",
     "iopub.status.busy": "2024-06-01T11:01:36.590056Z",
     "iopub.status.idle": "2024-06-01T11:01:36.596742Z",
     "shell.execute_reply": "2024-06-01T11:01:36.595940Z"
    },
    "papermill": {
     "duration": 0.016772,
     "end_time": "2024-06-01T11:01:36.598523",
     "exception": false,
     "start_time": "2024-06-01T11:01:36.581751",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_from_scratch_or_load(load_model_weight,new_model_name, epochs):\n",
    "    if load_model_weight==None:\n",
    "        #criterion = nn.MSELoss()\n",
    "        criterion = nn.HuberLoss()\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=0.01)\n",
    "        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.1, min_lr = 1e-8)\n",
    "        train_losses, test_losses=batch_gd_scheduler(model, new_model_name, criterion,\n",
    "                                                     optimizer,train_loader, val_loader,\n",
    "                                                      scheduler, epochs,\n",
    "                                                       device = device)\n",
    "        return train_losses, test_losses\n",
    "    else:\n",
    "        if torch.cuda.is_available():\n",
    "            trained_model = torch.load(load_model_weight)\n",
    "        else:\n",
    "            trained_model = torch.load(load_model_weight, map_location=torch.device('cpu'))\n",
    "        return trained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9dca561",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-01T11:01:36.614684Z",
     "iopub.status.busy": "2024-06-01T11:01:36.614420Z",
     "iopub.status.idle": "2024-06-01T11:01:36.620565Z",
     "shell.execute_reply": "2024-06-01T11:01:36.619702Z"
    },
    "papermill": {
     "duration": 0.016564,
     "end_time": "2024-06-01T11:01:36.622509",
     "exception": false,
     "start_time": "2024-06-01T11:01:36.605945",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_and_retrain(load_model_weight, new_model_name, epochs):\n",
    "    trained_model = torch.load(load_model_weight)\n",
    "    print('Trained model loaded')\n",
    "    criterion = nn.HuberLoss()\n",
    "    optimizer = torch.optim.AdamW(trained_model.parameters(),lr=0.01)\n",
    "    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.1, min_lr = 1e-7)\n",
    "    trained_model.train()\n",
    "    print('Begin retraining')\n",
    "    train_losses, test_losses=batch_gd_scheduler(trained_model,new_model_name, criterion, optimizer,\n",
    "                                                 train_loader, val_loader,\n",
    "                                                 scheduler, epochs,\n",
    "                                                 device = device)\n",
    "    return trained_model, train_losses, test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9561335a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-01T11:01:36.638519Z",
     "iopub.status.busy": "2024-06-01T11:01:36.638236Z",
     "iopub.status.idle": "2024-06-01T11:01:36.643656Z",
     "shell.execute_reply": "2024-06-01T11:01:36.642791Z"
    },
    "papermill": {
     "duration": 0.015642,
     "end_time": "2024-06-01T11:01:36.645548",
     "exception": false,
     "start_time": "2024-06-01T11:01:36.629906",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_losses(train_losses, test_losses):\n",
    "    # Plot the train loss and test loss per iteration\n",
    "    plt.plot(train_losses, label='train loss')\n",
    "    plt.plot(test_losses, label='val loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4110ee3a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-01T11:01:36.662045Z",
     "iopub.status.busy": "2024-06-01T11:01:36.661761Z",
     "iopub.status.idle": "2024-06-01T11:01:36.673142Z",
     "shell.execute_reply": "2024-06-01T11:01:36.672282Z"
    },
    "papermill": {
     "duration": 0.021913,
     "end_time": "2024-06-01T11:01:36.674992",
     "exception": false,
     "start_time": "2024-06-01T11:01:36.653079",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "################## GET PREDICTIONS + ACCURACY #####################\n",
    "def get_pred_n_acc(models, device, dataloader, num_iter):\n",
    "    i = 0\n",
    "    ypreds =[]\n",
    "    targets = []\n",
    "    #The last batch might not have size 128\n",
    "    while i< num_iter:\n",
    "        for data, target in dataloader:\n",
    "            #this empty list is to hold all models' preds\n",
    "            ypred = []\n",
    "            data= data.to(device)\n",
    "            data = data.to(torch.float32)\n",
    "            target = target.to(torch.float32)\n",
    "            #append the 'i^th' target\n",
    "            targets.append(target)\n",
    "            for model in models:\n",
    "                model.eval()\n",
    "                yp = model(data)\n",
    "                yp = yp.detach().cpu().numpy()\n",
    "                ypred.append(yp)\n",
    "            #take the mean of all models' predictions\n",
    "            ypred = np.array(ypred).mean(axis = 0)\n",
    "            ypred = np.round(ypred)\n",
    "            i+=1\n",
    "            #append ypred, targets inside the 'i' loop\n",
    "            # append the 'i^th' mean prediction\n",
    "            ypreds.append(ypred)\n",
    "            if i == num_iter:\n",
    "                break\n",
    "     #Do not convert ypreds, targets to np.array at this point,\n",
    "    #since the last batch has a different size, causing an error !\n",
    "    #CALCULATING ACCURACY\n",
    "    yp =  np.concatenate([ypreds[j] for j in range(len(ypreds))], axis = 0)\n",
    "    tgs =  np.concatenate([targets[j] for j in range(len(targets))], axis = 0)\n",
    "    h11_acc = ((yp[:,0] == tgs[:,0]).sum())/len(yp)\n",
    "    h21_acc = ((yp[:,1] == tgs[:,1]).sum())/len(yp)\n",
    "    h31_acc = ((yp[:,2] == tgs[:,2]).sum())/len(yp)\n",
    "    h22_acc = ((yp[:,3] == tgs[:,3]).sum())/len(yp)\n",
    "    acc = [h11_acc*100,h21_acc*100,h31_acc*100,h22_acc*100 ]\n",
    "    return  yp, tgs, acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492cc61a",
   "metadata": {
    "papermill": {
     "duration": 0.007193,
     "end_time": "2024-06-01T11:01:36.689664",
     "exception": false,
     "start_time": "2024-06-01T11:01:36.682471",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d9d7fc0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-01T11:01:36.706187Z",
     "iopub.status.busy": "2024-06-01T11:01:36.705521Z",
     "iopub.status.idle": "2024-06-01T15:47:54.198614Z",
     "shell.execute_reply": "2024-06-01T15:47:54.197560Z"
    },
    "papermill": {
     "duration": 17177.526081,
     "end_time": "2024-06-01T15:47:54.223138",
     "exception": false,
     "start_time": "2024-06-01T11:01:36.697057",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as LSTM-448-d80-fold4 at epoch 0\n",
      "Epoch: 0/550, train loss:  10.016, val_loss:  12.236, duration: 0:00:50.105229, learning rate: (0.01, 0.01)\n",
      "Model overwritten at epoch 1, new best val loss 9.62687604867139\n",
      "Model overwritten at epoch 2, new best val loss 9.623475186296616\n",
      "Model overwritten at epoch 4, new best val loss 8.481018015902755\n",
      "Model overwritten at epoch 5, new best val loss 8.386786030334177\n",
      "Model overwritten at epoch 6, new best val loss 8.347856157981287\n",
      "Model overwritten at epoch 10, new best val loss 8.338172476163294\n",
      "Epoch: 10/550, train loss:  8.446, val_loss:  8.338, duration: 0:00:49.876818, learning rate: (0.01, 0.01)\n",
      "Model overwritten at epoch 11, new best val loss 8.309571269962078\n",
      "Model overwritten at epoch 13, new best val loss 8.277110716355972\n",
      "Epoch: 20/550, train loss:  8.463, val_loss:  8.456, duration: 0:00:49.825752, learning rate: (0.01, 0.01)\n",
      "Model overwritten at epoch 25, new best val loss 8.255434151571194\n",
      "Model overwritten at epoch 26, new best val loss 8.250301162016045\n",
      "Model overwritten at epoch 27, new best val loss 8.092201066669487\n",
      "Model overwritten at epoch 28, new best val loss 7.330063774852971\n",
      "Model overwritten at epoch 29, new best val loss 7.030357103272023\n",
      "Epoch: 30/550, train loss:  7.067, val_loss:  7.072, duration: 0:00:49.387284, learning rate: (0.001, 0.001)\n",
      "Model overwritten at epoch 32, new best val loss 6.8310993860384475\n",
      "Model overwritten at epoch 33, new best val loss 6.673310779199491\n",
      "Model overwritten at epoch 34, new best val loss 6.554453526990979\n",
      "Model overwritten at epoch 35, new best val loss 6.442371312433497\n",
      "Model overwritten at epoch 36, new best val loss 6.375182333607013\n",
      "Model overwritten at epoch 37, new best val loss 6.317252958336449\n",
      "Model overwritten at epoch 38, new best val loss 6.146332143790303\n",
      "Model overwritten at epoch 39, new best val loss 5.945535889580938\n",
      "Epoch: 40/550, train loss:  6.022, val_loss:  6.359, duration: 0:00:49.609353, learning rate: (0.001, 0.001)\n",
      "Model overwritten at epoch 41, new best val loss 5.687881610294622\n",
      "Model overwritten at epoch 42, new best val loss 5.623496184597369\n",
      "Model overwritten at epoch 44, new best val loss 5.501411319094639\n",
      "Model overwritten at epoch 45, new best val loss 4.965956919191163\n",
      "Model overwritten at epoch 46, new best val loss 4.6687816464574805\n",
      "Model overwritten at epoch 48, new best val loss 4.457168977658305\n",
      "Epoch: 50/550, train loss:  4.372, val_loss:  4.521, duration: 0:00:48.869490, learning rate: (0.001, 0.001)\n",
      "Model overwritten at epoch 51, new best val loss 4.124739671952937\n",
      "Model overwritten at epoch 52, new best val loss 3.8395927175419162\n",
      "Model overwritten at epoch 53, new best val loss 3.593774223369723\n",
      "Model overwritten at epoch 55, new best val loss 3.574082141835818\n",
      "Model overwritten at epoch 56, new best val loss 3.5196726961885\n",
      "Model overwritten at epoch 57, new best val loss 3.2265717347743545\n",
      "Model overwritten at epoch 58, new best val loss 3.2030862027948555\n",
      "Model overwritten at epoch 59, new best val loss 2.999890518946029\n",
      "Epoch: 60/550, train loss:  2.973, val_loss:  3.284, duration: 0:00:49.238779, learning rate: (0.001, 0.001)\n",
      "Model overwritten at epoch 61, new best val loss 2.8779594119628342\n",
      "Model overwritten at epoch 62, new best val loss 2.5714080194825106\n",
      "Model overwritten at epoch 64, new best val loss 2.425549085226505\n",
      "Model overwritten at epoch 66, new best val loss 2.30528723593844\n",
      "Model overwritten at epoch 67, new best val loss 2.245765917825152\n",
      "Model overwritten at epoch 70, new best val loss 2.163301233159475\n",
      "Epoch: 70/550, train loss:  2.169, val_loss:  2.163, duration: 0:00:49.114751, learning rate: (0.001, 0.001)\n",
      "Model overwritten at epoch 71, new best val loss 2.1164022337411845\n",
      "Model overwritten at epoch 72, new best val loss 1.983756237290964\n",
      "Model overwritten at epoch 73, new best val loss 1.8927244422505203\n",
      "Model overwritten at epoch 74, new best val loss 1.8342233469080105\n",
      "Model overwritten at epoch 75, new best val loss 1.7867381076105695\n",
      "Model overwritten at epoch 79, new best val loss 1.7206321500195725\n",
      "Model overwritten at epoch 80, new best val loss 1.6595611267140347\n",
      "Epoch: 80/550, train loss:  1.676, val_loss:  1.660, duration: 0:00:48.848948, learning rate: (0.001, 0.001)\n",
      "Model overwritten at epoch 82, new best val loss 1.5273709754868092\n",
      "Model overwritten at epoch 86, new best val loss 1.5032431269154964\n",
      "Model overwritten at epoch 90, new best val loss 1.4660912564867699\n",
      "Epoch: 90/550, train loss:  1.360, val_loss:  1.466, duration: 0:00:48.895518, learning rate: (0.001, 0.001)\n",
      "Model overwritten at epoch 91, new best val loss 1.4327595364910675\n",
      "Model overwritten at epoch 92, new best val loss 1.4016068408369282\n",
      "Model overwritten at epoch 93, new best val loss 1.3188347061019183\n",
      "Model overwritten at epoch 96, new best val loss 1.2460943788211112\n",
      "Epoch: 100/550, train loss:  1.147, val_loss:  1.394, duration: 0:00:49.164234, learning rate: (0.001, 0.001)\n",
      "Model overwritten at epoch 102, new best val loss 1.2079419010209491\n",
      "Model overwritten at epoch 103, new best val loss 1.2000757034963354\n",
      "Model overwritten at epoch 105, new best val loss 1.1020865836505436\n",
      "Model overwritten at epoch 108, new best val loss 1.0938669162204806\n",
      "Epoch: 110/550, train loss:  1.006, val_loss:  1.256, duration: 0:00:48.909193, learning rate: (0.001, 0.001)\n",
      "Model overwritten at epoch 111, new best val loss 1.0694434214038124\n",
      "Model overwritten at epoch 112, new best val loss 1.0390007074491596\n",
      "Model overwritten at epoch 113, new best val loss 1.0175633856078112\n",
      "Model overwritten at epoch 114, new best val loss 0.9784738508769083\n",
      "Model overwritten at epoch 119, new best val loss 0.9689315420699561\n",
      "Model overwritten at epoch 120, new best val loss 0.9394639441636633\n",
      "Epoch: 120/550, train loss:  0.883, val_loss:  0.939, duration: 0:00:49.006029, learning rate: (0.001, 0.001)\n",
      "Model overwritten at epoch 122, new best val loss 0.9243266604058215\n",
      "Model overwritten at epoch 126, new best val loss 0.8891217550238149\n",
      "Model overwritten at epoch 129, new best val loss 0.87139571041842\n",
      "Epoch: 130/550, train loss:  0.783, val_loss:  0.889, duration: 0:00:48.921420, learning rate: (0.001, 0.001)\n",
      "Model overwritten at epoch 131, new best val loss 0.8063552234410608\n",
      "Model overwritten at epoch 138, new best val loss 0.8005797336665488\n",
      "Epoch: 140/550, train loss:  0.699, val_loss:  0.827, duration: 0:00:49.032809, learning rate: (0.001, 0.001)\n",
      "Model overwritten at epoch 144, new best val loss 0.7825418276694215\n",
      "Model overwritten at epoch 146, new best val loss 0.7573333998643921\n",
      "Model overwritten at epoch 148, new best val loss 0.7171863796483702\n",
      "Epoch: 150/550, train loss:  0.619, val_loss:  0.727, duration: 0:00:48.970938, learning rate: (0.001, 0.001)\n",
      "Model overwritten at epoch 151, new best val loss 0.7022915875764411\n",
      "Model overwritten at epoch 153, new best val loss 0.6708736012756351\n",
      "Model overwritten at epoch 154, new best val loss 0.6372185907337324\n",
      "Epoch: 160/550, train loss:  0.549, val_loss:  0.740, duration: 0:00:48.950810, learning rate: (0.001, 0.001)\n",
      "Model overwritten at epoch 162, new best val loss 0.6091726629847672\n",
      "Model overwritten at epoch 168, new best val loss 0.585941945648993\n",
      "Model overwritten at epoch 170, new best val loss 0.537230327580739\n",
      "Epoch: 170/550, train loss:  0.506, val_loss:  0.537, duration: 0:00:48.971589, learning rate: (0.001, 0.001)\n",
      "Model overwritten at epoch 176, new best val loss 0.5199762783740751\n",
      "Epoch: 180/550, train loss:  0.449, val_loss:  0.539, duration: 0:00:48.997495, learning rate: (0.001, 0.001)\n",
      "Model overwritten at epoch 185, new best val loss 0.49149723741614704\n",
      "Model overwritten at epoch 189, new best val loss 0.48012159823950473\n",
      "Model overwritten at epoch 190, new best val loss 0.46115215667190534\n",
      "Epoch: 190/550, train loss:  0.408, val_loss:  0.461, duration: 0:00:48.973427, learning rate: (0.001, 0.001)\n",
      "Model overwritten at epoch 197, new best val loss 0.4424006874358244\n",
      "Epoch: 200/550, train loss:  0.389, val_loss:  0.446, duration: 0:00:48.979929, learning rate: (0.001, 0.001)\n",
      "Model overwritten at epoch 202, new best val loss 0.43391053491688786\n",
      "Model overwritten at epoch 205, new best val loss 0.42240596168723027\n",
      "Model overwritten at epoch 207, new best val loss 0.39190870428758706\n",
      "Epoch: 210/550, train loss:  0.368, val_loss:  0.408, duration: 0:00:48.799902, learning rate: (0.001, 0.001)\n",
      "Model overwritten at epoch 215, new best val loss 0.3893797459164659\n",
      "Model overwritten at epoch 219, new best val loss 0.3715385014202778\n",
      "Epoch: 220/550, train loss:  0.344, val_loss:  0.425, duration: 0:00:48.967731, learning rate: (0.001, 0.001)\n",
      "Model overwritten at epoch 222, new best val loss 0.3702234388160579\n",
      "Model overwritten at epoch 224, new best val loss 0.36913422953472236\n",
      "Model overwritten at epoch 226, new best val loss 0.36828436536117665\n",
      "Model overwritten at epoch 229, new best val loss 0.358360939997019\n",
      "Epoch: 230/550, train loss:  0.321, val_loss:  0.374, duration: 0:00:49.124527, learning rate: (0.001, 0.001)\n",
      "Model overwritten at epoch 236, new best val loss 0.35091240210861413\n",
      "Model overwritten at epoch 239, new best val loss 0.3339432720736077\n",
      "Model overwritten at epoch 240, new best val loss 0.3195293123150756\n",
      "Epoch: 240/550, train loss:  0.287, val_loss:  0.320, duration: 0:00:48.897294, learning rate: (0.001, 0.001)\n",
      "Epoch: 250/550, train loss:  0.273, val_loss:  0.369, duration: 0:00:48.939048, learning rate: (0.001, 0.001)\n",
      "Model overwritten at epoch 252, new best val loss 0.17257217218193563\n",
      "Model overwritten at epoch 253, new best val loss 0.15537992796457034\n",
      "Model overwritten at epoch 254, new best val loss 0.1459753098096189\n",
      "Model overwritten at epoch 255, new best val loss 0.13979119387276912\n",
      "Model overwritten at epoch 256, new best val loss 0.13657112490625795\n",
      "Model overwritten at epoch 257, new best val loss 0.1348525177019945\n",
      "Model overwritten at epoch 258, new best val loss 0.12910653942733977\n",
      "Model overwritten at epoch 260, new best val loss 0.1272039606588558\n",
      "Epoch: 260/550, train loss:  0.038, val_loss:  0.127, duration: 0:00:49.045485, learning rate: (0.0001, 0.0001)\n",
      "Model overwritten at epoch 261, new best val loss 0.12502181101573956\n",
      "Model overwritten at epoch 262, new best val loss 0.1246736680058021\n",
      "Model overwritten at epoch 263, new best val loss 0.12098243575138742\n",
      "Model overwritten at epoch 265, new best val loss 0.11877844618289794\n",
      "Model overwritten at epoch 267, new best val loss 0.11710233445996904\n",
      "Model overwritten at epoch 270, new best val loss 0.11652526139081945\n",
      "Epoch: 270/550, train loss:  0.023, val_loss:  0.117, duration: 0:00:49.289410, learning rate: (0.0001, 0.0001)\n",
      "Model overwritten at epoch 271, new best val loss 0.11630465713841717\n",
      "Model overwritten at epoch 272, new best val loss 0.11567513121247608\n",
      "Model overwritten at epoch 273, new best val loss 0.11468229266434303\n",
      "Model overwritten at epoch 276, new best val loss 0.11340218724556339\n",
      "Model overwritten at epoch 277, new best val loss 0.11153657732421281\n",
      "Epoch: 280/550, train loss:  0.018, val_loss:  0.113, duration: 0:00:49.024876, learning rate: (0.0001, 0.0001)\n",
      "Model overwritten at epoch 285, new best val loss 0.11011850447389844\n",
      "Model overwritten at epoch 288, new best val loss 0.1100948581542731\n",
      "Epoch: 290/550, train loss:  0.016, val_loss:  0.113, duration: 0:00:48.959689, learning rate: (0.0001, 0.0001)\n",
      "Model overwritten at epoch 291, new best val loss 0.10997718276368866\n",
      "Model overwritten at epoch 294, new best val loss 0.10976184005639454\n",
      "Model overwritten at epoch 298, new best val loss 0.10911192645344288\n",
      "Epoch: 300/550, train loss:  0.015, val_loss:  0.110, duration: 0:00:49.056681, learning rate: (0.0001, 0.0001)\n",
      "Model overwritten at epoch 301, new best val loss 0.10787740425064515\n",
      "Model overwritten at epoch 308, new best val loss 0.1077726832923906\n",
      "Epoch: 310/550, train loss:  0.014, val_loss:  0.109, duration: 0:00:48.961834, learning rate: (0.0001, 0.0001)\n",
      "Model overwritten at epoch 320, new best val loss 0.10368790213653238\n",
      "Epoch: 320/550, train loss:  0.009, val_loss:  0.104, duration: 0:00:48.923037, learning rate: (1e-05, 1e-05)\n",
      "Model overwritten at epoch 321, new best val loss 0.10315138354917228\n",
      "Model overwritten at epoch 322, new best val loss 0.10291756081599529\n",
      "Model overwritten at epoch 324, new best val loss 0.1028865170200657\n",
      "Model overwritten at epoch 326, new best val loss 0.10283772322692022\n",
      "Model overwritten at epoch 328, new best val loss 0.10281418899644662\n",
      "Epoch: 330/550, train loss:  0.004, val_loss:  0.103, duration: 0:00:48.919404, learning rate: (1e-05, 1e-05)\n",
      "Epoch: 340/550, train loss:  0.004, val_loss:  0.103, duration: 0:00:48.937163, learning rate: (1.0000000000000002e-06, 1.0000000000000002e-06)\n",
      "Max patience reached, training is terminated at epoch 349\n"
     ]
    }
   ],
   "source": [
    "load_model_weight = None\n",
    "epochs = 550\n",
    "new_model_name = 'LSTM-448-d80-fold4'\n",
    "if load_model_weight is None:\n",
    "    train_losses, test_losses=train_from_scratch_or_load(load_model_weight,new_model_name,  epochs)\n",
    "else:\n",
    "    model, train_losses, test_losses=load_and_retrain(load_model_weight, new_model_name, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "499ee588",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-01T15:47:54.262205Z",
     "iopub.status.busy": "2024-06-01T15:47:54.261885Z",
     "iopub.status.idle": "2024-06-01T15:47:54.466009Z",
     "shell.execute_reply": "2024-06-01T15:47:54.464959Z"
    },
    "papermill": {
     "duration": 0.226012,
     "end_time": "2024-06-01T15:47:54.468066",
     "exception": false,
     "start_time": "2024-06-01T15:47:54.242054",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_losses(train_losses, test_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85303623",
   "metadata": {
    "papermill": {
     "duration": 0.019075,
     "end_time": "2024-06-01T15:47:54.506714",
     "exception": false,
     "start_time": "2024-06-01T15:47:54.487639",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "946770be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-01T15:47:54.545974Z",
     "iopub.status.busy": "2024-06-01T15:47:54.545696Z",
     "iopub.status.idle": "2024-06-01T15:48:19.420050Z",
     "shell.execute_reply": "2024-06-01T15:48:19.418979Z"
    },
    "papermill": {
     "duration": 24.896339,
     "end_time": "2024-06-01T15:48:19.422056",
     "exception": false,
     "start_time": "2024-06-01T15:47:54.525717",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data, target shapes: ((579638, 4), (579638, 4)),\n",
      " train accuracies [99.98481811061387, 99.89821233252478, 99.94669086567824, 99.90183528340101]\n",
      "Validation data, target shapes: ((144909, 4), (144909, 4)),\n",
      " validation accuracies [99.70326204721583, 97.53569481536688, 93.81128846379451, 79.07307344609376]\n"
     ]
    }
   ],
   "source": [
    "#Train accuracy\n",
    "yt, tgt, acct = get_pred_n_acc([model], device, train_loader, num_iter = len(train_loader))\n",
    "#validation accuracy\n",
    "yv, tgv, accv = get_pred_n_acc([model], device, val_loader, num_iter = len(val_loader))\n",
    "print(f'Train data, target shapes: {yt.shape, tgt.shape},\\n train accuracies {acct}')\n",
    "print(f'Validation data, target shapes: {yv.shape, tgv.shape},\\n validation accuracies {accv}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b955c4f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-01T15:48:19.463219Z",
     "iopub.status.busy": "2024-06-01T15:48:19.462922Z",
     "iopub.status.idle": "2024-06-01T15:48:25.498604Z",
     "shell.execute_reply": "2024-06-01T15:48:25.497515Z"
    },
    "papermill": {
     "duration": 6.058617,
     "end_time": "2024-06-01T15:48:25.500793",
     "exception": false,
     "start_time": "2024-06-01T15:48:19.442176",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data, target shapes: ((181137, 4), (181137, 4)),\n",
      " test accuracies [99.71182033488465, 97.56648282791478, 93.87093746722094, 78.84639803022023]\n"
     ]
    }
   ],
   "source": [
    "#Test accuracy\n",
    "yts, tgts, accts = get_pred_n_acc([model], device, test_loader, num_iter = len(test_loader))\n",
    "print(f'Test data, target shapes: {yts.shape, tgts.shape},\\n test accuracies {accts}')\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4575883,
     "sourceId": 8488978,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 180758667,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30665,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 17242.470367,
   "end_time": "2024-06-01T15:48:27.889969",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-06-01T11:01:05.419602",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
